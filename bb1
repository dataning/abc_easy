import streamlit as st
import pandas as pd
import json
import time
from datetime import datetime
import io
import base64
import os

# Import the proxy setup and main analysis functions
# Note: Save your enhanced script as 'news_analysis.py' in the same directory
from news_analysis import (
    setup_corporate_proxy,
    test_proxy_connection,
    extract_knowledge_graph_with_llm,
    build_search_term_list,
    fetch_articles_for_terms_parallel,
    split_articles_by_subject,
    deduplicate_by_title_and_reputation,
    remove_exact_duplicates_only,
    format_dates,
    calculate_semantic_similarity_efficient,
    add_news_id_and_filter,
    generate_summary_with_llm,
    GenericLLMClient
)

# Initialize proxy configuration first
setup_corporate_proxy()

# Typing animation functions
def display_summary_with_typing_effect(summary_text: str, speed: int = 5):
    """Display summary with word-by-word typing animation"""
    # Split summary into sections
    lines = summary_text.split('\n')
    
    # Calculate delay based on speed (1-10 scale, where 10 is fastest)
    delay = 0.1 / speed  # Faster speed = smaller delay
    
    current_section = []
    
    for line in lines:
        if line.startswith('ğŸ“Š') or line.startswith('ğŸ¯') or line.startswith('ğŸ”') or \
           line.startswith('ğŸ“…') or line.startswith('ğŸ“‹') or line.startswith('ğŸ“ˆ'):
            # Display accumulated section if any
            if current_section:
                display_section_animated(current_section, delay)
            
            # Start new section with header
            current_section = []
            if line.startswith('ğŸ“Š'):
                st.markdown("### " + line)
            elif any(line.startswith(emoji) for emoji in ['ğŸ¯', 'ğŸ”', 'ğŸ“…', 'ğŸ“‹', 'ğŸ“ˆ']):
                st.markdown("#### " + line)
        else:
            current_section.append(line)
    
    # Display final section if any
    if current_section:
        display_section_animated(current_section, delay)

def display_section_animated(lines: list, delay: float):
    """Animate a section of text line by line with typing effect"""
    # Create a placeholder for the entire section
    section_placeholder = st.empty()
    animated_text = []
    
    for line in lines:
        if not line.strip():  # Empty line
            animated_text.append("")
            continue
        
        # For bullet points or special formatting, show the marker immediately
        if line.strip().startswith(('â€¢', '-', '*', '1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.')):
            # Find where the actual content starts
            marker_end = line.find(' ', line.find('.') + 1 if '.' in line[:3] else 0)
            if marker_end == -1:
                marker_end = len(line)
            
            marker = line[:marker_end+1]
            content = line[marker_end+1:]
            
            # Animate the content word by word
            words = content.split()
            animated_line = marker
            
            for i, word in enumerate(words):
                animated_line += word + " "
                animated_text_copy = animated_text.copy()
                animated_text_copy.append(animated_line.rstrip())
                
                # Update the display
                section_placeholder.markdown('\n'.join(animated_text_copy))
                time.sleep(delay)
            
            animated_text.append(line)
        else:
            # Regular line - animate word by word
            words = line.split()
            animated_line = ""
            
            for i, word in enumerate(words):
                animated_line += word + " "
                animated_text_copy = animated_text.copy()
                animated_text_copy.append(animated_line.rstrip())
                
                # Update the display
                section_placeholder.markdown('\n'.join(animated_text_copy))
                time.sleep(delay)
            
            animated_text.append(line)
    
    # Final update with complete text
    section_placeholder.markdown('\n'.join(animated_text))

def display_summary_instant(summary_text: str):
    """Display summary instantly without animation"""
    lines = summary_text.split('\n')
    current_section = []
    
    for line in lines:
        if line.startswith('ğŸ“Š') or line.startswith('ğŸ¯') or line.startswith('ğŸ”') or \
           line.startswith('ğŸ“…') or line.startswith('ğŸ“‹') or line.startswith('ğŸ“ˆ'):
            if current_section:
                st.markdown('\n'.join(current_section))
            current_section = [line]
            if line.startswith('ğŸ“Š'):
                st.markdown("### " + line)
            elif any(line.startswith(emoji) for emoji in ['ğŸ¯', 'ğŸ”', 'ğŸ“…', 'ğŸ“‹', 'ğŸ“ˆ']):
                st.markdown("#### " + line)
        else:
            current_section.append(line)
    
    if current_section:
        st.markdown('\n'.join(current_section))

# Page configuration
st.set_page_config(
    page_title="News Analysis Dashboard",
    page_icon="ğŸ“°",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
    <style>
    .main {
        padding-top: 2rem;
    }
    .stButton>button {
        width: 100%;
        background-color: #1f77b4;
        color: white;
        font-weight: bold;
    }
    .stButton>button:hover {
        background-color: #0056b3;
    }
    .summary-box {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        margin-top: 20px;
    }
    .metric-card {
        background-color: #ffffff;
        padding: 15px;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin-bottom: 10px;
    }
    .stExpander {
        background-color: #f8f9fa;
        border-radius: 10px;
    }
    </style>
    """, unsafe_allow_html=True)

# Initialize session state
if 'analysis_complete' not in st.session_state:
    st.session_state.analysis_complete = False
if 'df_results' not in st.session_state:
    st.session_state.df_results = pd.DataFrame()
if 'summary' not in st.session_state:
    st.session_state.summary = ""
if 'knowledge_graph' not in st.session_state:
    st.session_state.knowledge_graph = {}
if 'search_terms' not in st.session_state:
    st.session_state.search_terms = []
if 'llm_client' not in st.session_state:
    st.session_state.llm_client = None
if 'proxy_status' not in st.session_state:
    st.session_state.proxy_status = False

# Header
st.title("ğŸ“° Advanced News Analysis Dashboard")
st.markdown("**Powered by LLM-based relevance scoring and semantic analysis**")

# Sidebar configuration
with st.sidebar:
    st.header("âš™ï¸ Configuration")
    
    # Proxy status indicator
    proxy_configured = os.environ.get('HTTPS_PROXY', '') != ''
    if proxy_configured:
        st.success(f"âœ… Proxy: {os.environ.get('HTTPS_PROXY')}")
    else:
        st.warning("âš ï¸ No proxy configured")
    
    # Test proxy connection button
    if st.button("ğŸ” Test Proxy Connection"):
        with st.spinner("Testing proxy..."):
            proxy_ok = test_proxy_connection()
            st.session_state.proxy_status = proxy_ok
            if proxy_ok:
                st.success("âœ… Proxy connection successful!")
            else:
                st.error("âŒ Proxy connection failed!")
    
    st.markdown("---")
    
    # LLM Provider selection
    llm_provider = st.selectbox(
        "LLM Provider",
        ["cerebras", "openai", "groq", "gemini"],
        help="Select the LLM provider for analysis"
    )
    
    # Initialize LLM client when provider changes
    if st.session_state.llm_client is None or st.session_state.llm_client.provider != llm_provider:
        try:
            st.session_state.llm_client = GenericLLMClient(llm_provider)
            st.success(f"âœ… {llm_provider.title()} client initialized")
        except Exception as e:
            st.error(f"âŒ Failed to initialize {llm_provider}: {str(e)}")
    
    # Processing options
    st.subheader("ğŸ“‹ Processing Options")
    
    dedup_option = st.radio(
        "Deduplication Method",
        ["No deduplication", "Exact matches only", "Fuzzy matching (85% threshold)"],
        help="Choose how to handle duplicate articles"
    )
    
    generate_summary = st.checkbox(
        "Generate AI Summary",
        value=True,
        help="Generate a comprehensive summary of the results"
    )
    
    max_records = st.slider(
        "Max records per search term",
        min_value=50,
        max_value=500,
        value=250,
        step=50,
        help="Maximum number of articles to fetch per search term"
    )
    
    # Advanced options
    with st.expander("ğŸ”§ Advanced Options"):
        batch_size_translation = st.number_input(
            "Translation batch size",
            min_value=5,
            max_value=20,
            value=10,
            help="Number of headlines to translate in parallel"
        )
        
        batch_size_relevance = st.number_input(
            "Relevance scoring batch size",
            min_value=3,
            max_value=10,
            value=5,
            help="Number of articles to score in parallel"
        )
        
        top_articles_summary = st.number_input(
            "Top articles for summary",
            min_value=5,
            max_value=25,
            value=15,
            help="Number of top articles to use for summary generation"
        )

# Main content area
col1, col2 = st.columns([2, 1])

with col1:
    # Query input
    query = st.text_input(
        "ğŸ” Enter your search query",
        placeholder="e.g., Harvard endowment performance",
        help="Enter a specific query about news you want to analyze"
    )

with col2:
    # Analyze button
    st.markdown("<br>", unsafe_allow_html=True)
    analyze_button = st.button("ğŸš€ Analyze News", type="primary")

# Analysis process
if analyze_button and query:
    if st.session_state.llm_client is None:
        st.error("âŒ Please initialize an LLM provider first!")
    else:
        # Reset session state
        st.session_state.analysis_complete = False
        st.session_state.df_results = pd.DataFrame()
        st.session_state.summary = ""
        
        # Progress tracking
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            # Step 1: Knowledge Graph Extraction
            status_text.text("ğŸ§  Extracting knowledge graph...")
            progress_bar.progress(10)
            
            # Override the global llm_client with the session state one
            import news_analysis
            news_analysis.llm_client = st.session_state.llm_client
            
            kg = extract_knowledge_graph_with_llm(query)
            st.session_state.knowledge_graph = kg
            
            # Step 2: Build search terms
            status_text.text("ğŸ”¤ Building search terms...")
            progress_bar.progress(20)
            
            terms = build_search_term_list(kg)
            st.session_state.search_terms = terms
            
            # Display extracted information
            with st.expander("ğŸ“Š Knowledge Graph Analysis", expanded=True):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("Entities Identified")
                    if kg.get('entities'):
                        for entity in kg['entities']:
                            st.write(f"â€¢ **{entity['text']}** ({entity['type']})")
                    else:
                        st.write("No entities identified")
                    
                    st.subheader("Action Nodes")
                    if kg.get('action_nodes'):
                        for node in kg['action_nodes']:
                            st.write(f"â€¢ {node}")
                    else:
                        st.write("No action nodes identified")
                
                with col2:
                    st.subheader(f"Search Terms ({len(terms)})")
                    # Show first 10 terms
                    for i, term in enumerate(terms[:10]):
                        st.write(f"{i+1}. {term}")
                    if len(terms) > 10:
                        st.write(f"... and {len(terms)-10} more terms")
            
            # Step 3: Fetch articles
            status_text.text(f"ğŸ“¥ Fetching articles for {len(terms)} search terms...")
            progress_bar.progress(30)
            
            all_articles = fetch_articles_for_terms_parallel(terms, max_records=max_records)
            
            if all_articles.empty:
                st.error("âŒ No articles found. Try modifying your query.")
                progress_bar.progress(100)
            else:
                st.success(f"âœ… Found {len(all_articles)} total articles")
                
                # Step 4: Process articles
                status_text.text("ğŸ”„ Processing and deduplicating articles...")
                progress_bar.progress(50)
                
                # Determine deduplication method
                remove_duplicates = dedup_option == "Fuzzy matching (85% threshold)"
                remove_exact_only = dedup_option == "Exact matches only"
                
                # Get main subject entity
                subject = kg['entities'][0]['text'] if kg.get('entities') else None
                
                if subject:
                    df_processed = split_articles_by_subject(
                        all_articles, 
                        subject, 
                        query, 
                        remove_duplicates, 
                        remove_exact_only
                    )
                else:
                    # Basic processing without subject
                    if remove_duplicates:
                        df_processed = deduplicate_by_title_and_reputation(all_articles)
                    elif remove_exact_only:
                        df_processed = remove_exact_duplicates_only(all_articles)
                    else:
                        df_processed = all_articles.copy()
                    
                    df_processed = format_dates(df_processed)
                    df_processed = calculate_semantic_similarity_efficient(df_processed, query)
                
                # Step 5: Add IDs and filter
                status_text.text("ğŸ†” Adding article IDs and filtering...")
                progress_bar.progress(70)
                
                if not df_processed.empty:
                    df_filtered = add_news_id_and_filter(df_processed)
                    st.session_state.df_results = df_filtered
                    
                    # Step 6: Generate summary
                    if generate_summary and not df_filtered.empty:
                        status_text.text("ğŸ“ Generating AI summary...")
                        progress_bar.progress(90)
                        
                        summary = generate_summary_with_llm(df_filtered, query)
                        st.session_state.summary = summary
                    
                    progress_bar.progress(100)
                    status_text.text("âœ… Analysis complete!")
                    st.session_state.analysis_complete = True
                    
        except Exception as e:
            st.error(f"âŒ Error during analysis: {str(e)}")
            if "proxy" in str(e).lower() or "connection" in str(e).lower():
                st.warning("This might be a proxy-related issue. Check proxy settings in the sidebar.")
            progress_bar.progress(100)
            status_text.text("Analysis failed")

# Display results
if st.session_state.analysis_complete and not st.session_state.df_results.empty:
    
    # Results metrics
    st.markdown("---")
    st.header("ğŸ“Š Analysis Results")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total Articles", len(st.session_state.df_results))
    
    with col2:
        high_relevance = len(st.session_state.df_results[st.session_state.df_results['score_geo'] > 0.5])
        st.metric("High Relevance", high_relevance)
    
    with col3:
        avg_score = st.session_state.df_results['score_geo'].mean()
        st.metric("Avg. Relevance", f"{avg_score:.3f}")
    
    with col4:
        date_range = f"{st.session_state.df_results['Date'].min()} to {st.session_state.df_results['Date'].max()}"
        st.metric("Date Range", date_range)
    
    # Display summary with typing animation
    if st.session_state.summary:
        st.markdown("---")
        st.header("ğŸ“ AI-Generated Summary")
        
        # Add a control for typing speed
        col1, col2, col3 = st.columns([1, 1, 2])
        with col1:
            typing_speed = st.slider("Typing Speed", min_value=1, max_value=10, value=5, help="Higher = Faster")
        with col2:
            skip_animation = st.button("â­ï¸ Skip Animation")
        
        # Format and display summary with typing effect
        summary_container = st.container()
        
        # Check if we should animate or not
        should_animate = 'summary_animated' not in st.session_state or not st.session_state.summary_animated
        
        if skip_animation:
            should_animate = False
            st.session_state.summary_animated = True
        
        with summary_container:
            if should_animate and not skip_animation:
                # Animate the summary
                display_summary_with_typing_effect(st.session_state.summary, typing_speed)
                st.session_state.summary_animated = True
            else:
                # Display without animation (instant)
                display_summary_instant(st.session_state.summary)
    
    # Articles table
    st.markdown("---")
    st.header("ğŸ“° Article Details")
    
    # Filtering options
    col1, col2, col3 = st.columns(3)
    
    with col1:
        min_score = st.slider(
            "Minimum relevance score",
            min_value=0.0,
            max_value=1.0,
            value=0.0,
            step=0.1
        )
    
    with col2:
        selected_domains = st.multiselect(
            "Filter by domain",
            options=st.session_state.df_results['domain'].unique(),
            default=[]
        )
    
    with col3:
        sort_by = st.selectbox(
            "Sort by",
            ["score_geo", "Date", "semantic_similarity", "llm_relevance_score"],
            index=0
        )
    
    # Apply filters
    filtered_df = st.session_state.df_results.copy()
    
    if min_score > 0:
        filtered_df = filtered_df[filtered_df['score_geo'] >= min_score]
    
    if selected_domains:
        filtered_df = filtered_df[filtered_df['domain'].isin(selected_domains)]
    
    # Sort
    filtered_df = filtered_df.sort_values(sort_by, ascending=False)
    
    # Display table
    if not filtered_df.empty:
        # Select columns to display
        display_cols = [
            'news_id', 'english_title', 'Date', 'domain', 
            'semantic_similarity', 'llm_relevance_score', 'score_geo',
            'llm_reasoning', 'url'
        ]
        
        # Check which columns exist
        available_cols = [col for col in display_cols if col in filtered_df.columns]
        
        # Create a styled dataframe
        st.dataframe(
            filtered_df[available_cols],
            use_container_width=True,
            height=400,
            hide_index=True,
            column_config={
                "news_id": st.column_config.TextColumn("ID", width="small"),
                "english_title": st.column_config.TextColumn("Title", width="large"),
                "Date": st.column_config.DateColumn("Date", width="small"),
                "domain": st.column_config.TextColumn("Source", width="small"),
                "semantic_similarity": st.column_config.NumberColumn("Semantic", format="%.3f", width="small"),
                "llm_relevance_score": st.column_config.NumberColumn("LLM Score", format="%.3f", width="small"),
                "score_geo": st.column_config.NumberColumn("Combined", format="%.3f", width="small"),
                "llm_reasoning": st.column_config.TextColumn("Reasoning", width="medium"),
                "url": st.column_config.LinkColumn("Link", width="small")
            }
        )
        
        # Download options
        st.markdown("---")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # Download filtered results as CSV
            csv = filtered_df.to_csv(index=False)
            b64 = base64.b64encode(csv.encode()).decode()
            href = f'<a href="data:file/csv;base64,{b64}" download="news_analysis_results.csv">ğŸ“¥ Download Results (CSV)</a>'
            st.markdown(href, unsafe_allow_html=True)
        
        with col2:
            # Download summary as text
            if st.session_state.summary:
                summary_text = st.session_state.summary
                b64 = base64.b64encode(summary_text.encode()).decode()
                href = f'<a href="data:text/plain;base64,{b64}" download="news_analysis_summary.txt">ğŸ“„ Download Summary (TXT)</a>'
                st.markdown(href, unsafe_allow_html=True)
        
        with col3:
            # Download full analysis as JSON
            analysis_data = {
                "query": query,
                "timestamp": datetime.now().isoformat(),
                "knowledge_graph": st.session_state.knowledge_graph,
                "search_terms": st.session_state.search_terms,
                "summary": st.session_state.summary,
                "articles": filtered_df.to_dict(orient='records'),
                "llm_provider": st.session_state.llm_client.provider if st.session_state.llm_client else "Unknown",
                "proxy_configured": proxy_configured
            }
            json_str = json.dumps(analysis_data, indent=2, default=str)
            b64 = base64.b64encode(json_str.encode()).decode()
            href = f'<a href="data:application/json;base64,{b64}" download="news_analysis_full.json">ğŸ“‹ Download Full Analysis (JSON)</a>'
            st.markdown(href, unsafe_allow_html=True)
    
    else:
        st.warning("No articles match the current filters")

# Footer
st.markdown("---")
st.markdown(
    f"""
    <div style='text-align: center; color: #666;'>
        <p>News Analysis Dashboard | Powered by GDELT, LLMs, and Semantic Analysis</p>
        <p>Built with Streamlit ğŸˆ | Proxy: {'âœ… Configured' if proxy_configured else 'âŒ Not configured'}</p>
    </div>
    """,
    unsafe_allow_html=True
)
